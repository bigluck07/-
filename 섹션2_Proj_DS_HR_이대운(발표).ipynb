{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "섹션2_Proj-DS_HR-이대운(발표).ipynb",
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": [
        "-YnQxpGOCVVU",
        "Uj9uQMIGCYMe"
      ],
      "toc_visible": true,
      "authorship_tag": "ABX9TyNJD2H2ibiSsNx0yQ8dMhbA",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/bigluck07/Code_States_Project/blob/main/%EC%84%B9%EC%85%982_Proj_DS_HR_%EC%9D%B4%EB%8C%80%EC%9A%B4(%EB%B0%9C%ED%91%9C).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yx17nQgP71Sb"
      },
      "source": [
        "# 데이터\n",
        "\n",
        "해당 데이터는 kaggle의  **R Analytics: Job Change of Data Scientists**의 데이터 셋입니다.\n",
        "\n",
        "https://www.kaggle.com/arashnic/hr-analytics-job-change-of-data-scientists\n",
        "\n",
        "\n",
        "### Note :\n",
        "- 데이터 세트가 불균형합니다.\n",
        "- 대부분의 기능은 범주 형 (명목, 순서, 이진)이며 일부는 카디널리티가 높습니다.\n",
        "- 누락 된 대치도 파이프 라인의 일부가 될 수 있습니다.\n",
        "\n",
        "\n",
        "### 특성설명:\n",
        "- enrollee_id : 후보자의 고유 ID\n",
        "- city : 도시 코드\n",
        "- city_ development _index : 도시 개발 지수 (축척)\n",
        "- gender : 후보자의 성별\n",
        "- relevent_experience : 후보자의 관련 경험\n",
        "- enrolled_university : 등록 된 대학 과정 유형 (있는 경우)\n",
        "- education_level : 지원자의 교육 수준\n",
        "- major_discipline : 후보자 교육 전공\n",
        "- experience : 근무기간(년)\n",
        "- company_size : 현재 고용주 회사의 직원 수\n",
        "- company_type : 현재 고용주의 유형\n",
        "- lastnewjob : 이전 직장과 현재 직장 간의 연도 차이\n",
        "- training_hours : 완료된 교육 시간\n",
        "- target : 0 – 전직을 찾고 있지 않음, 1 – 전직을 찾고 있음"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j4X7fJsc7neV"
      },
      "source": [
        "## **1) 데이터 선정 이유 및 문제 정의**\n",
        "\n",
        "### 시나리오\n",
        "빅데이터와 데이터 사이언스에 활동하는 'Data State'는 회사가 진행하는 일부 과정을 성공적으로 통과한 사람들 중에서 **데이터 과학자를 고용**하기를 원합니다. \n",
        "\n",
        "많은 사람들이 회사의 교육에 신청하므로 데이터의 양에는 문제가 없습니다. \n",
        "\n",
        "기업은 이들 후보자 중 누가 훈련이나 신규 취업을 원하는지 알고 싶어하는데, 이는 교육의 질이나 과정 계획, 후보자의 분류뿐 아니라 비용과 시간을 줄이는 데 도움이 되기 때문입니다. \n",
        "\n",
        "인구통계학, 교육, 경험과 관련된 정보는 후보자 등록과 정규 수강생 등록에서 수집하였습니다.\n",
        "\n",
        "\n",
        "이 데이터 세트는 인사 연구를 위해 현재 직장을 그만두게 하는 요인을 이해하기 위해 고안되었습니다. \n",
        "\n",
        "현재 자격 증명, 인구 통계, 경험 데이터를 사용하는 모델에 의해 당신은 후보자가 새로운 일자리를 찾거나 회사에서 일할 확률을 예측할 뿐만 아니라 직원 결정에 영향을 미치는 요인을 해석하게 됩니다.\n",
        "\n",
        "학습 및 테스트를 위해 분할 된 전체 데이터이며, 샘플 제출은 enrolee _id, target 열과 함께 제공된 테스트 세트의 enrollee_id에 해당합니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zpQeLqBp5JUg"
      },
      "source": [
        "# 분석"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f5B1QBWL7roU"
      },
      "source": [
        "## **2) 데이터를 이용한 가설 및 평가지표, 베이스라인 선택**\n",
        "가설:\n",
        "1. 도시개발점수가 낮은 곳에 사는 교육생은 도시개발점수가 높은곳으로 이직하고 싶어할 것이다.\n",
        "2. 근속 3년 이상인 교육생은 이직하려고 할 것이다.\n",
        "3. training_hours가 높은 교육생은 이직하고자 할 것이다.\n",
        "\n",
        "### **태스크를 수행한 후, 다음 질문에 대답할 수 있어야 합니다.**\n",
        "\n",
        "1. target = 이직을 했는지, 안했는지\n",
        " - 교육생의 데이터를 통해 이직하고자 하는 교육생을 판별하고, 이직을 권유하기 위해서\n",
        "2. 해당 베이스라인 모델과 평가지표를 선택한 이유를 설명하세요.\n",
        " - 베이스라인: train데이터의 target변수의 value_ciunts 중 결과치가 높은 value로 모든 결과를 예측한다고 했을때 갖게되는 모델로, 예측을 하지않고 target변수가 가지고 있는 요소 중 함유량이 높은 요소로 모든 예측값을 결정한 기본이 되는 모델이다. 따라서 해당 베이스라인은 '모든 교육생이 이직을 원하지 않는다'를 예측하고 틀린부분들은 이직을 할 교육생이라는 의미를 가지고 있다.\n",
        "\n",
        " - 평가지표 \n",
        "    - 'accuracy': 모델의 정확도를 확인해주는 평가지표로 예측에 대한 맞은 정도를 알려준다. 따라서 기준모델에서는 2개의 요소 중 가장많은 요소의 비율이 보여진다고 할 수 있다.\n",
        "\n",
        "    - 'AUC': 'accuracy'의 단점이될 수 있는 모델이 한 요소로 모두 찍었을 경우 보일 수 있는 높은 정확도를 구분할 수 있는 지표로 사용하면서도, 고정수치이기때문에 얼마나 모델이 잘 예측하는지 절대적 수치로 측정할 수 있으며, 분류 임계치가 고정되어있기에, 모델의 분류 임계점이 어떠한지에 관계없이 모델이 잘 예측하는지 측정할 수 있다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "51-U1kkr4wXs"
      },
      "source": [
        "# Google Colab을 사용하는 경우 해당 셀을 실행하세요\n",
        "%%capture\n",
        "import sys\n",
        "\n",
        "if 'google.colab' in sys.modules:\n",
        "    # Install packages in Colab\n",
        "    !pip install category_encoders==2.*\n",
        "    !pip install eli5\n",
        "    !pip install pandas-profiling==2.*\n",
        "    !pip install pdpbox\n",
        "    !pip install shap\n",
        "    !pip install lightgbm"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D994YmSe5Au3"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C4zvsnPq5CIB"
      },
      "source": [
        "# data read\n",
        "data = pd.read_csv('/content/aug_train.csv')\n",
        "data.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fb3h486sJ6R8"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "train, test = train_test_split(data, test_size=0.2, random_state=2)\n",
        "train.shape, test.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZZFysa8bCPGt"
      },
      "source": [
        "#### 기준모델"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bkaDDZeNJmil"
      },
      "source": [
        "# 기준모델\n",
        "target='target'\n",
        "print(train[target].value_counts())\n",
        "\n",
        "# 기준모델 정확도 계산\n",
        "from sklearn.metrics import accuracy_score, roc_auc_score\n",
        "major = train[target].mode()[0]\n",
        "y_pred = [major] * len(train[target])\n",
        "print(\"baseline accuracy: \", accuracy_score(train[target], y_pred))\n",
        "print('AUC score: ', roc_auc_score(train[target], y_pred))\n",
        "\n",
        "# baseline accuracy:  0.7512070990473705\n",
        "# AUC score:  0.5"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5mn6KZY57uWb"
      },
      "source": [
        "## **3) EDA와 데이터 전처리**\n",
        "\n",
        "가설을 정했고 베이스라인을 만들었다면 데이터의 탐색 및 가공을 시작해봅니다. 바로 적용이 될 수 있는 데이터도 있겠지만, 대부분의 데이터는 전처리 작업이 필요합니다.\n",
        "데이터 전처리를 통해 할 수 있는 것은 다양하지만 다음을 시도해볼 수 있습니다.\n",
        "\n",
        "- EDA\n",
        "- Feature Engineering\n",
        "- 데이터의 정규화\n",
        "- 노이즈 제거\n",
        "- 결측치 제거 혹은 대체\n",
        "- 데이터 밸런스\n",
        "- 그 외\n",
        "\n",
        "### **태스크를 수행한 후, 다음 질문에 대답할 수 있어야 합니다**\n",
        "\n",
        "1. Data Leakage가 있었나요? 없었다면 어떻게 방지했나요?\n",
        "- 분류모델이라 target 피쳐를 사용하여 FE를 하거나, 연관된 피쳐가 없다.\n",
        "\n",
        "2. 만들고자 하는 모델은 언제 유용한가요? 어떤 한계를 가지고 있나요?\n",
        "-"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BZg2JXrfzAvi"
      },
      "source": [
        "print(train.shape, '\\n')\n",
        "train.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5vLauChvzo70"
      },
      "source": [
        "# 칼럼확인\n",
        "train.columns"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "REQ3Jia60GGL"
      },
      "source": [
        "# 형식확인\n",
        "train.dtypes"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pJ_1gx4b0SsN"
      },
      "source": [
        "# describe\n",
        "train.describe(include='all').T"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jEimJsv89Ss9"
      },
      "source": [
        "# 결측치 확인\n",
        "[(x, train[x].isnull().sum()) for x in train.columns if train[x].isnull().any()]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vAhO_Yxxyynu"
      },
      "source": [
        "from pandas_profiling import ProfileReport\n",
        "#profile = ProfileReport(train, minimal=True).to_notebook_iframe()\n",
        "\n",
        "# Warnings\n",
        "\n",
        "# 'city' has a high cardinality: 123 distinct values\tHigh cardinality\n",
        "# 'enrollee_id' unique values"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-YnQxpGOCVVU"
      },
      "source": [
        "#### EDA"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BpyP4Y05808U"
      },
      "source": [
        "# EDA\n",
        "def removecity(i):\n",
        "  i = i.replace('city_','')\n",
        "  i = int(i)\n",
        "  return i\n",
        "\n",
        "def clear(df):\n",
        "  # target 형변환\n",
        "  df['target'] = df['target'].apply(int)\n",
        "\n",
        "  # city의 인코딩을 순서적으로 만들기\n",
        "  df['city'] = df['city'].apply(removecity)\n",
        "\n",
        "  # city_development_index 소수점 셋째자리 반올림\n",
        "  df.loc[:, \"city_development_index\"] = round(df.loc[:, \"city_development_index\"],3)\n",
        "\n",
        "  # 10% 이하 결측치 제거\n",
        "  df.dropna(subset=[\"experience\"], inplace=True)\n",
        "  df.dropna(subset=[\"enrolled_university\"], inplace=True)\n",
        "  df.dropna(subset=[\"last_new_job\"], inplace=True)\n",
        "  df.dropna(subset=[\"education_level\"], inplace=True)\n",
        "\n",
        "  # 10% 초과 결측치는 imputer 활용\n",
        "\n",
        "    # 무의미한 피쳐 삭제\n",
        "  need_del = ['enrollee_id']\n",
        "  df = df.drop(need_del, axis=1)\n",
        "  \n",
        "  return df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kqZh6okP82TY"
      },
      "source": [
        "train_cl = clear(train)\n",
        "test_cl = clear(test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "spCyC2rf5hcn"
      },
      "source": [
        "train_cl['city_development_index'].unique()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-UDwJ6IdJKr-"
      },
      "source": [
        "train_cl.shape, test_cl.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pD5hTr_ZEdeh"
      },
      "source": [
        "feature = train.columns.drop('target')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Uj9uQMIGCYMe"
      },
      "source": [
        "#### FE"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ED83oq9oHSTg"
      },
      "source": [
        "# Feature Engineering - 건질게 없느냐\n",
        "\n",
        "# # city_development_index, city\n",
        "# city_dvp = pd.DataFrame(df.groupby('city_development_index')['city'].value_counts())\n",
        "# train['city_development_index'].unique()\n",
        "\n",
        "# company_size company_type\n",
        "# company = df['company_type'] + ',' + df['company_size'] - 하나가 NaN이면 NaN으로 표시됨..;;\n",
        "\n",
        "# del feature\n",
        "# need_del = ['company_type','company_size']\n",
        "# df = df.drop(need_del, axis=1)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uvZ3NafhhyM7"
      },
      "source": [
        "# train_cl.loc[:, [\"company_size\",\"company_type\"]].isna()#.value_counts()# and train_cl.loc[:, \"company_type\"].isna()]\n",
        "# train_cl[train_cl.loc[:, \"company_size\"].isna() == train_cl.loc[:, \"company_type\"].isna()].isna().sum()\n",
        "# train_cl[train_cl.loc[:, \"company_size\"].isna() != train_cl.loc[:, \"company_type\"].isna()]['company_size'].value_counts()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rahNuCDN7wb0"
      },
      "source": [
        "## **4) 머신러닝 방식 적용 및 교차검증**\n",
        "\n",
        "데이터의 탐색과 전처리 작업이 끝났다면 모델링을 통해 베이스라인과의 성능 비교를 해봅니다.\n",
        "\n",
        "- Linear / Tree-based / Ensemble / Boosting 모델을 학습하세요. (다양하게 시도해보시는 걸 추천합니다.)\n",
        "- 평가지표를 계산 후 베이스라인과 비교해보세요.\n",
        "- 어느정도 성능이 나왔다면, 교차 검증 (이하 CV)을 통해서 일반화될 가능성이 있는지 확인해봅니다.\n",
        "- 모델 성능을 개선하기 위한 다양한 방법을 적용해보세요.\n",
        "    - Hyperparameter tuning, etc.\n",
        "- 최소 2개 이상의 모델을 만들어서 validation 점수를 보고하세요.\n",
        "- 최종 모델의 test 점수를 보고하세요.\n",
        "\n",
        "### **태스크를 수행한 후, 다음 질문에 대답할 수 있어야 합니다.**\n",
        "\n",
        "1. 모델을 학습한 후에 베이스라인보다 잘 나왔나요? 그렇지 않다면 그 이유는 무엇일까요?\n",
        " - 잘나왔습니다. 아마 결측치가 별로없는 데이터는 삭제하고, 평균값으로 나머지를 채워서 그런거 같습니다.\n",
        "2. 모델 성능 개선을 위해 어떤 방법을 적용했나요? 그 방법을 선택한 이유는 무엇인가요?\n",
        " - 랜더마이즈cv를 통해 최적의 하이퍼파라미터값을 찾았습니다. 파라미터를 개별적으로 손대는것은 너무나 많은 시간이 들기때문에, 임의적으로돌린 후 최적의 하이퍼 파라미터를 찾았습니다.\n",
        "3. 최종 모델에 관해 설명하세요.\n",
        " - LBGM에 랜더마이즈cv를 사용후 Boosting을 활용한 모델로 랜더마이즈cv로 최적의 하이퍼파라미터를 찾고, 해당 값을 통해 부스팅을 한 모델입니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MNgckK3CO0GO"
      },
      "source": [
        "# data split\n",
        "from sklearn.model_selection import train_test_split\n",
        "train_f, val_f = train_test_split(train_cl, test_size=0.2, random_state=2)\n",
        "\n",
        "\n",
        "target = 'target'\n",
        "feature = train_f.columns.drop(target)\n",
        "\n",
        "X_train = train_f[feature]\n",
        "y_train = train_f[target]\n",
        "X_val = val_f[feature]\n",
        "y_val = val_f[target]\n",
        "X_test = test_cl[feature]\n",
        "y_test = test_cl[target]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E9pIZu7mB2_f"
      },
      "source": [
        "# action_type: ordi\n",
        "from category_encoders import TargetEncoder\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "from sklearn.pipeline import make_pipeline\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from lightgbm import LGBMClassifier, plot_importance\n",
        "\n",
        "from sklearn.metrics import classification_report, f1_score\n",
        "from sklearn.model_selection import RandomizedSearchCV"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8kHqAnX6eagC"
      },
      "source": [
        "# 기준모델\n",
        "target='target'\n",
        "train[target].value_counts()\n",
        "\n",
        "# 기준모델 정확도 계산\n",
        "from sklearn.metrics import accuracy_score\n",
        "major = train[target].mode()[0]\n",
        "y_pred = [major] * len(train[target])\n",
        "print(\"baseline accuracy: \", accuracy_score(train[target], y_pred))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ji00qfsJCi95"
      },
      "source": [
        "####  Tree-based"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wm6lv_RwCxZN"
      },
      "source": [
        "# make pipe\n",
        "Tree_based_pipe = make_pipeline(\n",
        "    TargetEncoder(smoothing=10.0), \n",
        "    SimpleImputer(strategy='median'), \n",
        "    StandardScaler(),\n",
        "    DecisionTreeClassifier(random_state=2, max_depth=4)\n",
        ")\n",
        "\n",
        "Tree_based_pipe.fit(X_train,y_train)\n",
        "\n",
        "print('모델 정확도', Tree_based_pipe.score(X_train, y_train))\n",
        "print('검증 정확도', Tree_based_pipe.score(X_val, y_val))\n",
        "\n",
        "y_pred_proba = Tree_based_pipe.predict_proba(X_val)[:, -1]\n",
        "print('\\n')\n",
        "print('AUC score: ', roc_auc_score(y_val, y_pred_proba))\n",
        "\n",
        "\n",
        "from sklearn.metrics import roc_auc_score\n",
        "from sklearn.metrics import roc_curve\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "fpr, tpr, thresholds = roc_curve(y_val, y_pred_proba)\n",
        "\n",
        "plt.scatter(fpr, tpr, color='blue')\n",
        "plt.plot(fpr, tpr, color='green')\n",
        "plt.title('ROC curve')\n",
        "plt.xlabel('FPR')\n",
        "plt.ylabel('TPR')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PoaIskRU2Xb1"
      },
      "source": [
        "##### best parameter"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eE_OUOU-2cJC"
      },
      "source": [
        "# find best parameter - RandomizedSearchCV\n",
        "from scipy.stats import randint, uniform\n",
        "\n",
        "\n",
        "Tree_based_pipe = make_pipeline(\n",
        "    TargetEncoder(), \n",
        "    SimpleImputer(), \n",
        "    StandardScaler(), \n",
        "    DecisionTreeClassifier(random_state=2)\n",
        ")\n",
        "\n",
        "\n",
        "dists = {\n",
        "    'targetencoder__smoothing': [2.,20.,50.,60.,100.,500.,1000.], # int로 넣으면 error(bug)\n",
        "    'targetencoder__min_samples_leaf': randint(1, 10),     \n",
        "    'simpleimputer__strategy': ['mean', 'median'], \n",
        "    'decisiontreeclassifier__max_depth' : [2,4,6,8,10,12,None]\n",
        "}\n",
        "\n",
        "Tree_based_clf = RandomizedSearchCV(\n",
        "    Tree_based_pipe, \n",
        "    param_distributions=dists, \n",
        "    n_iter=10, \n",
        "    cv=3,\n",
        "    scoring='neg_mean_absolute_error',  \n",
        "    verbose=1,\n",
        "    n_jobs=-1\n",
        ")\n",
        "\n",
        "Tree_based_clf.fit(X_train, y_train);\n",
        "Tree_based_pipe_rd = Tree_based_clf.best_estimator_"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cYr1-l5LFVXv"
      },
      "source": [
        "print('최적 하이퍼파라미터: ', Tree_based_clf.best_params_)\n",
        "print('MAE: ', -Tree_based_clf.best_score_)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y0HsXOhD4RGy"
      },
      "source": [
        "print('모델 정확도', Tree_based_pipe_rd .score(X_train, y_train))\n",
        "print('검증 정확도', Tree_based_pipe_rd .score(X_val, y_val))\n",
        "\n",
        "y_pred_proba = Tree_based_pipe_rd .predict_proba(X_val)[:, -1]\n",
        "print('\\n')\n",
        "print('AUC score: ', roc_auc_score(y_val, y_pred_proba))\n",
        "\n",
        "\n",
        "from sklearn.metrics import roc_auc_score\n",
        "from sklearn.metrics import roc_curve\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "fpr, tpr, thresholds = roc_curve(y_val, y_pred_proba)\n",
        "\n",
        "plt.scatter(fpr, tpr, color='blue')\n",
        "plt.plot(fpr, tpr, color='green')\n",
        "plt.title('ROC curve')\n",
        "plt.xlabel('FPR')\n",
        "plt.ylabel('TPR')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sCLkwRdLGOju"
      },
      "source": [
        "#### Ensemble"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-XmxYI_VQs2x"
      },
      "source": [
        "# make pipe\n",
        "Ensemble_pipe = make_pipeline(\n",
        "    TargetEncoder(smoothing=10.0), \n",
        "    SimpleImputer(strategy='median'), \n",
        "    StandardScaler(), \n",
        "    RandomForestClassifier(random_state=2, max_depth=7, n_jobs=-1, n_estimators=50)\n",
        ")\n",
        "\n",
        "Ensemble_pipe.fit(X_train,y_train)\n",
        "print('모델 정확도', Ensemble_pipe.score(X_train, y_train))\n",
        "print('검증 정확도', Ensemble_pipe.score(X_val, y_val))\n",
        "\n",
        "y_pred_proba = Ensemble_pipe.predict_proba(X_val)[:, -1]\n",
        "print('\\n')\n",
        "print('AUC score: ', roc_auc_score(y_val, y_pred_proba))\n",
        "print('\\n')\n",
        "\n",
        "\n",
        "fpr, tpr, thresholds = roc_curve(y_val, y_pred_proba)\n",
        "\n",
        "plt.scatter(fpr, tpr, color='blue')\n",
        "plt.plot(fpr, tpr, color='green')\n",
        "plt.title('ROC curve')\n",
        "plt.xlabel('FPR')\n",
        "plt.ylabel('TPR')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZIN0uyro2fD_"
      },
      "source": [
        "##### best parameter"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Giu9UI422hUG"
      },
      "source": [
        "# find best parameter - RandomizedSearchCV\n",
        "from scipy.stats import randint, uniform\n",
        "\n",
        "Ensemble_pipe = make_pipeline(\n",
        "    TargetEncoder(),\n",
        "    SimpleImputer(),\n",
        "    StandardScaler(), \n",
        "    RandomForestClassifier(random_state=2)\n",
        ")\n",
        "\n",
        "dists = {\n",
        "    'targetencoder__smoothing': [2.,20.,50.,60.,100.,500.,1000.], # int로 넣으면 error(bug)\n",
        "    'targetencoder__min_samples_leaf': randint(1, 10),     \n",
        "    'simpleimputer__strategy': ['mean', 'median'], \n",
        "    'randomforestclassifier__n_estimators': randint(50, 1000), \n",
        "    'randomforestclassifier__max_depth': [2,4,6,8,10,12,None],\n",
        "    'randomforestclassifier__max_features': uniform(0, 1) \n",
        "}\n",
        "\n",
        "Ensemble_clf = RandomizedSearchCV(\n",
        "    Ensemble_pipe, \n",
        "    param_distributions=dists, \n",
        "    n_iter=10, \n",
        "    cv=3,\n",
        "    scoring='neg_mean_absolute_error',  \n",
        "    verbose=1,\n",
        "    n_jobs=-1\n",
        ")\n",
        "\n",
        "Ensemble_clf.fit(X_train, y_train);\n",
        "Ensemble_pipe_rd = Ensemble_clf.best_estimator_"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m8AUkTdSFc3U"
      },
      "source": [
        "print('최적 하이퍼파라미터: ', Ensemble_clf.best_params_)\n",
        "print('MAE: ', -Ensemble_clf.best_score_)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eYMz69Xs56Pi"
      },
      "source": [
        "print('모델 정확도', Ensemble_pipe_rd .score(X_train, y_train))\n",
        "print('검증 정확도', Ensemble_pipe_rd .score(X_val, y_val))\n",
        "\n",
        "y_pred_proba = Ensemble_pipe_rd .predict_proba(X_val)[:, -1]\n",
        "print('\\n')\n",
        "print('AUC score: ', roc_auc_score(y_val, y_pred_proba))\n",
        "\n",
        "\n",
        "from sklearn.metrics import roc_auc_score\n",
        "from sklearn.metrics import roc_curve\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "fpr, tpr, thresholds = roc_curve(y_val, y_pred_proba)\n",
        "\n",
        "plt.scatter(fpr, tpr, color='blue')\n",
        "plt.plot(fpr, tpr, color='green')\n",
        "plt.title('ROC curve')\n",
        "plt.xlabel('FPR')\n",
        "plt.ylabel('TPR')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kiyH9wIlKhJz"
      },
      "source": [
        "#### Boosting"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iXPWhPovXk7W"
      },
      "source": [
        "from category_encoders import OrdinalEncoder\n",
        "\n",
        "encoder = TargetEncoder(smoothing=10.0)\n",
        "X_train_encoded = encoder.fit_transform(X_train, y_train) # 학습데이터\n",
        "X_val_encoded = encoder.transform(X_val) # 검증데이터\n",
        "\n",
        "imputer = SimpleImputer(strategy='median')\n",
        "X_train_im = imputer.fit_transform(X_train_encoded)\n",
        "X_val_im = imputer.transform(X_val_encoded)\n",
        "\n",
        "boosting = LGBMClassifier(random_state=2, \n",
        "                          max_depth=3, \n",
        "                          n_jobs=-1, \n",
        "                          n_estimators=1000, \n",
        "                          num_leaves=31,\n",
        "                          learning_rate=0.2)\n",
        "\n",
        "eval_set = [(X_train_im, y_train), \n",
        "            (X_val_im, y_val)]\n",
        "\n",
        "boosting.fit(X_train_im, y_train, \n",
        "          eval_set=eval_set,\n",
        "          early_stopping_rounds=50\n",
        "         )\n",
        "# training's binary_logloss: 0.421149\t\n",
        "# valid_1's binary_logloss: 0.423476"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8tjeu-ZLmyIT"
      },
      "source": [
        "s = X_train['city'].unique()\n",
        "s"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CidWfnUbmw2l"
      },
      "source": [
        "X_train_encoded['city'].unique()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rVeaFv1Y0ruc"
      },
      "source": [
        "\n",
        "y_pred = boosting.predict(X_val_im)\n",
        "print('모델 정확도', boosting.score(X_train_im, y_train))\n",
        "print('검증 정확도', boosting.score(X_val_im, y_val))\n",
        "\n",
        "y_pred_proba = boosting.predict_proba(X_val_im)[:, -1]\n",
        "print('\\n')\n",
        "print('AUC score: ', roc_auc_score(y_val, y_pred_proba))\n",
        "print('\\n')\n",
        "\n",
        "fpr, tpr, thresholds = roc_curve(y_val, y_pred_proba)\n",
        "\n",
        "plt.scatter(fpr, tpr, color='blue')\n",
        "plt.plot(fpr, tpr, color='green')\n",
        "plt.title('ROC curve')\n",
        "plt.xlabel('FPR')\n",
        "plt.ylabel('TPR')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kGCg8mCSWtUe"
      },
      "source": [
        "##### Best parameter"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xA704sj2DMTU"
      },
      "source": [
        "# find best parameter - RandomizedSearchCV\n",
        "from scipy.stats import randint, uniform\n",
        "\n",
        "Boosting_pipe = make_pipeline(\n",
        "    TargetEncoder(),\n",
        "    SimpleImputer(),\n",
        "    StandardScaler(), \n",
        "    LGBMClassifier(random_state=2)\n",
        ")\n",
        "\n",
        "dists = {\n",
        "    'targetencoder__smoothing': [2.,20.,50.,60.,100.,500.,1000.], # int로 넣으면 error(bug)\n",
        "    'targetencoder__min_samples_leaf': randint(1, 10),     \n",
        "    'simpleimputer__strategy': ['mean', 'median'], \n",
        "    'lgbmclassifier__n_estimators': randint(50, 1000), \n",
        "    'lgbmclassifier__max_features': uniform(0, 1),\n",
        "    'lgbmclassifier__num_leaves':[10,20,30,40],\n",
        "    'lgbmclassifier__learning_rate': [0.1,0.2,0.3,0.4],\n",
        "    'lgbmclassifier__max_depth': [2,4,6,8,10,12,None]\n",
        "}\n",
        "\n",
        "boosting_clf = RandomizedSearchCV(\n",
        "    Boosting_pipe, \n",
        "    param_distributions=dists, \n",
        "    n_iter=10, \n",
        "    cv=3,\n",
        "    scoring='neg_mean_absolute_error',  \n",
        "    verbose=1,\n",
        "    n_jobs=-1\n",
        ")\n",
        "\n",
        "boosting_clf.fit(X_train, y_train);\n",
        "Boosting_pipe_rd = boosting_clf.best_estimator_"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gYHHIS0kD-2x"
      },
      "source": [
        "print('최적 하이퍼파라미터: ', boosting_clf.best_params_)\n",
        "print('MAE: ', -boosting_clf.best_score_)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YDaioo12fNNM"
      },
      "source": [
        "encoder = TargetEncoder(smoothing=500.0, min_samples_leaf=8)\n",
        "X_train_encoded = encoder.fit_transform(X_train, y_train) # 학습데이터\n",
        "X_val_encoded = encoder.transform(X_val) # 검증데이터\n",
        "X_test_encoded = encoder.transform(X_test) # 테스트데이터\n",
        "\n",
        "imputer = SimpleImputer(strategy='median')\n",
        "X_train_im = imputer.fit_transform(X_train_encoded)\n",
        "X_val_im = imputer.transform(X_val_encoded)\n",
        "X_test_im = imputer.transform(X_test_encoded)\n",
        "\n",
        "boosting_rd = LGBMClassifier(random_state=2, \n",
        "                          max_depth=None, \n",
        "                          n_jobs=-1, \n",
        "                          n_estimators=102, \n",
        "                          num_leaves=20,\n",
        "                          learning_rate=0.1,\n",
        "                          max_features = 0.665)\n",
        "\n",
        "eval_set = [(X_train_im, y_train), \n",
        "            (X_val_im, y_val)]\n",
        "\n",
        "boosting_rd.fit(X_train_im, y_train, \n",
        "          eval_set=eval_set,\n",
        "          early_stopping_rounds=50\n",
        "         )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vaz4ECF4Pudu"
      },
      "source": [
        "y_pred = boosting_rd.predict(X_val_im)\n",
        "print('모델 정확도', boosting_rd.score(X_train_im, y_train))\n",
        "print('검증 정확도', boosting_rd.score(X_val_im, y_val))\n",
        "\n",
        "y_pred_proba = boosting_rd.predict_proba(X_val_im)[:, -1]\n",
        "print('\\n')\n",
        "print('AUC score: ', roc_auc_score(y_val, y_pred_proba))\n",
        "print('\\n')\n",
        "\n",
        "fpr, tpr, thresholds = roc_curve(y_val, y_pred_proba)\n",
        "\n",
        "plt.scatter(fpr, tpr, color='blue')\n",
        "plt.plot(fpr, tpr, color='green')\n",
        "plt.title('ROC curve')\n",
        "plt.xlabel('FPR')\n",
        "plt.ylabel('TPR')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8m3-RGOcObUE"
      },
      "source": [
        "#### 모델 비교\n",
        "##### tree-based 모델\n",
        "- 기본\n",
        "  - 검증 정확도 0.7930675909878683\n",
        "  - AUC score:  0.7933806367649752\n",
        "\n",
        "- 랜더마이즈cv\n",
        "  - 검증 정확도 0.7937608318890814\n",
        "  - AUC score:  0.7958575078287049\n",
        "\n",
        "##### Ensemble 모델\n",
        "- 기본\n",
        "  - 검증 정확도 0.8031195840554592\n",
        "  - AUC score:  0.8128968741029947\n",
        "\n",
        "- 랜더마이즈cv\n",
        "  - 검증 정확도 0.8055459272097054\n",
        "  - AUC score:  0.8129621403698811\n",
        "\n",
        "##### Boosting 모델\n",
        "- 기본\n",
        "  - 검증 정확도 0.8010398613518197\n",
        "  - AUC score:  0.8148762928240876\n",
        "\n",
        "- 랜더마이즈cv_부스팅\n",
        "  - 검증 정확도 0.8010398613518197\n",
        "  - AUC score:  0.8161819428696117\n",
        "\n",
        "\n",
        "##### 가장높은 AUC 모델: Boosting모델의 랜더마이즈cv+부스팅"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "plbxs4ql6jHM"
      },
      "source": [
        "#### 최종모델"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sa1qdJmm6k4G"
      },
      "source": [
        "y_pred = boosting_rd.predict(X_test_im)\n",
        "\n",
        "y_pred_proba = boosting_rd.predict_proba(X_test_im)[:, -1]\n",
        "print('\\n')\n",
        "print('AUC score: ', roc_auc_score(y_test, y_pred_proba))\n",
        "print('\\n')\n",
        "\n",
        "fpr, tpr, thresholds = roc_curve(y_test, y_pred_proba)\n",
        "\n",
        "plt.scatter(fpr, tpr, color='blue')\n",
        "plt.plot(fpr, tpr, color='green')\n",
        "plt.title('ROC curve')\n",
        "plt.xlabel('FPR')\n",
        "plt.ylabel('TPR')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kOIezFCm7yxT"
      },
      "source": [
        "## **5) 머신러닝 모델 해석**\n",
        "\n",
        "프로젝트에서 가장 중요하다고 볼 수 있는 부분 입니다. 우리는 SHAP, PDP 등을 통해서 모델이 관측치를 어떤 특성을 활용했거나, 어떤 특성이 타겟에 영향을 끼쳤는지 등을 해석하는 방법에 대해서 배웠습니다.\n",
        "여러분의 프로젝트에도 이러한 해석 방법을 활용해 머신러닝 모델을 비전문가라도 조금 더 쉽게 이해하고 접근할 수 있도록 해주셔야 합니다.\n",
        "\n",
        "- PDP, SHAP을 활용하여 최종 모델을 설명합니다\n",
        "- 시각화는 \"설명\"이 제일 중요합니다.\n",
        "\n",
        "### **태스크를 수행한 후, 다음 질문에 대답할 수 있어야 합니다.**\n",
        "\n",
        "1. 모델이 관측치를 예측하기 위해서 어떤 특성을 활용했나요?\n",
        "2. 어떤 특성이 있다면 모델의 예측에 도움이 될까요? 해당 특성은 어떻게 구할 수 있을까요?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iADao2ukR5LS"
      },
      "source": [
        "# dpi(dots per inch) 수치를 조정해 이미지 화질 조정\n",
        "import matplotlib.pyplot as plt\n",
        "plt.rcParams['figure.dpi'] = 144\n",
        "\n",
        "# 그래프 그리기\n",
        "from pdpbox.pdp import pdp_isolate, pdp_plot\n",
        "\n",
        "model = boosting_rd\n",
        "\n",
        "# 그래프를 그려야하는 특성\n",
        "features = X_train_encoded.columns\n",
        "# 그래프를 그리는 함수\n",
        "def pdp_plt(feature):\n",
        "  isolated = pdp_isolate(\n",
        "      model=model, # 모델\n",
        "      dataset=X_val_encoded, #검증데이터\n",
        "      model_features=X_train_encoded.columns, \n",
        "      feature=feature, # 확인하고자 하는 특성\n",
        "      grid_type='percentile', # default='percentile', or 'equal' # percentile: 데이터의 분포대로 해줌, equal: 점을 균일하게 찍어줌\n",
        "      num_grid_points=100 # default=10\n",
        "  )\n",
        "  return pdp_plot(isolated, feature_name=feature);"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_UCr1_90sjlX"
      },
      "source": [
        "features = X_train_encoded.columns\n",
        "for i in features:\n",
        "  pdp_plt(i)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_3TdKKfhCKtf"
      },
      "source": [
        "### 가설확인"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h1gcAVNSRbv7"
      },
      "source": [
        "#### 가설1\n",
        "1. 도시개발점수가 낮은 곳에 사는 교육생은 도시개발점수가 높은곳으로 이직하고 싶어할 것이다.\n",
        "  - pdp 'city_development_index' 확인\n",
        "   > 0.6이하에서 이직이 빈번하게 일어나며, 0.92인 도시들는 이직율이 높다\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k6qL4yfLSAHr"
      },
      "source": [
        "# 양의 관계 - city, city_development_index, gender, relevent_experience, enrolled_university, education_level, major_disciline, experience, company_size, company_type\n",
        "pdp_plt('city_development_index')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sRnDkoAMPF10"
      },
      "source": [
        "# 2 features\n",
        "from pdpbox.pdp import pdp_interact, pdp_interact_plot\n",
        "features = ['city', 'city_development_index']\n",
        "\n",
        "# 두 특성상의 의존성을 확인\n",
        "interaction = pdp_interact(\n",
        "    model=boosting_rd, \n",
        "    dataset=X_train_encoded,\n",
        "    model_features=X_train_encoded.columns, \n",
        "    features=features\n",
        ")\n",
        "\n",
        "pdp_interact_plot(interaction, plot_type='grid', \n",
        "                  feature_names=features);"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nz4a7qHsRfi2"
      },
      "source": [
        "#### 가설2\n",
        "2. 근속 3년 이상인 교육생은 이직하려고 할 것이다.\n",
        "  > 4,2,3년차 순으로 이직률이 높으며 1년차에서도 일어난다.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hz7geP_xVM2H"
      },
      "source": [
        "pdp_plt('last_new_job')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zn48wqd9Rns-"
      },
      "source": [
        "#### 가설3\n",
        "3. training_hours가 높은 교육생은 이직하고자 할 것이다.\n",
        " > 150시간 이하의 교육 받은 교육생이 이직을 하는 경향이 크다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_mGxPMIUV9xE"
      },
      "source": [
        "pdp_plt('training_hours')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AB5UfU-4cYqD"
      },
      "source": [
        "### SHAP"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0pTltFyDXClV"
      },
      "source": [
        "# 1. force plot - all\n",
        "shap.initjs()\n",
        "\n",
        "import shap\n",
        "\n",
        "explainer = shap.TreeExplainer(model)\n",
        "shap_values = explainer.shap_values(X_train_encoded[:100])\n",
        "shap.force_plot(explainer.expected_value[1], shap_values[1], X_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7Opydw7pfgqH"
      },
      "source": [
        "shap_values = explainer.shap_values(X_train_encoded)\n",
        "shap.summary_plot(shap_values[0], X_train_encoded, plot_type='bar')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UVvSOP6abiEf"
      },
      "source": [
        "### PDP"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZiYnpqq4bg3Q"
      },
      "source": [
        "# 양의 관계 - city, city_development_index, gender, relevent_experience, enrolled_university, education_level, major_disciline, experience, company_size, company_type\n",
        "# 애매한괸계 - last_new_job, training_hours"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "frKy9RQmyqTm"
      },
      "source": [
        "# permutation importance\n",
        "import eli5\n",
        "from eli5.sklearn import PermutationImportance\n",
        "\n",
        "permuter = PermutationImportance(\n",
        "    model,\n",
        "    scoring='neg_mean_absolute_error', \n",
        "    n_iter=5,\n",
        "    random_state=2\n",
        ")\n",
        "\n",
        "permuter.fit(X_train_encoded, y_train);\n",
        "\n",
        "import pandas as pd\n",
        "feature_names = X_train_encoded.columns.tolist()\n",
        "\n",
        "eli5.show_weights(\n",
        "    permuter, \n",
        "    top=None,\n",
        "    feature_names=feature_names\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "98FhJd4eVLCt"
      },
      "source": [
        "# 2 features\n",
        "from pdpbox.pdp import pdp_interact, pdp_interact_plot\n",
        "features = ['last_new_job', 'training_hours']\n",
        "\n",
        "# 두 특성상의 의존성을 확인\n",
        "interaction = pdp_interact(\n",
        "    model=boosting_rd, \n",
        "    dataset=X_train_encoded,\n",
        "    model_features=X_train_encoded.columns, \n",
        "    features=features\n",
        ")\n",
        "\n",
        "pdp_interact_plot(interaction, plot_type='grid', \n",
        "                  feature_names=features);"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t5PpR0aCir_w"
      },
      "source": [
        "# 2 features\n",
        "from pdpbox.pdp import pdp_interact, pdp_interact_plot\n",
        "features = ['company_type', 'company_size']\n",
        "\n",
        "# 두 특성상의 의존성을 확인\n",
        "interaction = pdp_interact(\n",
        "    model=boosting_rd, \n",
        "    dataset=X_train_encoded,\n",
        "    model_features=X_train_encoded.columns, \n",
        "    features=features\n",
        ")\n",
        "\n",
        "pdp_interact_plot(interaction, plot_type='grid', \n",
        "                  feature_names=features);"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FHwenRilmb-M"
      },
      "source": [
        "# 양의 관계 - city, city_development_index, gender, relevent_experience, enrolled_university, education_level, major_disciline, experience, company_size, company_type\n",
        "# 애매한괸계 - last_new_job, training_hours"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VFIW_6lrmPQh"
      },
      "source": [
        "### 결론\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XBFgZzIGLCxt"
      },
      "source": [
        "- clty: 지역번호가 높을 수록 이직이 빈번하며, 70-105, 160이상 의 도시들이 이직이 할 확률이 더 높다.\n",
        "- city_de_in: 0.6이하에서 이직이 빈번하게 일어나며, 0.9 전후의 몇 도시들안에서 이직이 일어난다.\n",
        "- gender: ahems 모든성별에서 이직이 일어나지만, 0.27(female)과 0.25(other)가 확률적으로 높다\n",
        "- relevent_experience: 둘다 이직을 하지만 관련경험이 없는경우 더 빈번하다\n",
        "- enrolled_university: 풀타임코스에서 이직이 더욱 빈번하다\n",
        "- education_level: 학력이 학사(0.27378286), 석사(0.20520194)인경우 빈번하다\n",
        "- major_discipline: 전공이 존재하면 이직을 할 경우가 높지만, STEM(0.2544967), Business Degree(0.25504855)의 경우 더 빈번하다\n",
        "- experience: 20년 이상의 경력이 있는 교육생 이외는 모두 이직할 가능성이 있지만, 1년미만과 1년, 3년의 경력을 가진 교육생이 가장 높다\n",
        "- company_size: 10/49의 규모를 가진 회사가 이직률이 가장 높지만 유의미 한 수치는 아니다.\n",
        "- company_type: 'Other','Early Stage Startup이 가장 높다\n",
        "- last_new_job: 4,2,3년차 순으로 이직률이 높으며 1년차에서도 일어난다.\n",
        "- training_hours: 150시간 이하의 교육시간을 갖은 교육생의 이직률이 높다"
      ]
    }
  ]
}